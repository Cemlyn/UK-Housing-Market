{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created by Tetsu Haruyama\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm,chi2\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import LikelihoodModel,LikelihoodModelResults,ResultMixin\n",
    "from statsmodels.tools.decorators import cache_readonly\n",
    "from statsmodels.tools.numdiff import approx_fprime\n",
    "\n",
    "#%% GenericLikelihoodModel_TobitTruncreg\n",
    "\n",
    "class GenericLikelihoodModel_TobitTruncreg(LikelihoodModel):\n",
    "    \"\"\"\n",
    "    This is based on GenericLikelihoodModel of statsmodels (0.9.0).\n",
    "    The modified part is indecated: see the following\n",
    "        * `cov_type`\n",
    "        * `genericmlefit`\n",
    "    The aim of this class: to make it possible to use GenericLikelihoodModelResults_TobitTruncreg (see below)\n",
    "    \"\"\"\n",
    "    def __init__(self, endog, exog=None, loglike=None, score=None,\n",
    "                 hessian=None, missing='none', extra_params_names=None,\n",
    "                 **kwds):\n",
    "\n",
    "        if loglike is not None:\n",
    "            self.loglike = loglike\n",
    "        if score is not None:\n",
    "            self.score = score\n",
    "        if hessian is not None:\n",
    "            self.hessian = hessian\n",
    "\n",
    "        self.__dict__.update(kwds)\n",
    "\n",
    "        super(GenericLikelihoodModel_TobitTruncreg, self).__init__(endog, exog,\n",
    "                                                     missing=missing)\n",
    "\n",
    "        if exog is not None:\n",
    "            self.nparams = (exog.shape[1] if np.ndim(exog) == 2 else 1)\n",
    "\n",
    "        if extra_params_names is not None:\n",
    "            self._set_extra_params_names(extra_params_names)\n",
    "\n",
    "    def _set_extra_params_names(self, extra_params_names):\n",
    "        # check param_names\n",
    "        if extra_params_names is not None:\n",
    "            if self.exog is not None:\n",
    "                self.exog_names.extend(extra_params_names)\n",
    "            else:\n",
    "                self.data.xnames = extra_params_names\n",
    "\n",
    "        self.nparams = len(self.exog_names)\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize (possibly re-initialize) a Model instance. For\n",
    "        instance, the design matrix of a linear model may change\n",
    "        and some things must be recomputed.\n",
    "        \"\"\"\n",
    "        if not self.score:\n",
    "            self.score = lambda x: approx_fprime(x, self.loglike)\n",
    "            if not self.hessian:\n",
    "                pass\n",
    "        else:\n",
    "            if not self.hessian:\n",
    "                pass\n",
    "\n",
    "        if self.exog is not None:\n",
    "            er = np.linalg.matrix_rank(self.exog)\n",
    "            self.df_model = float(er - 1)\n",
    "            self.df_resid = float(self.exog.shape[0] - er)\n",
    "        else:\n",
    "            self.df_model = np.nan\n",
    "            self.df_resid = np.nan\n",
    "        super(GenericLikelihoodModel_TobitTruncreg, self).initialize()\n",
    "\n",
    "    def expandparams(self, params):\n",
    "        \"\"\"\n",
    "        expand to full parameter array when some parameters are fixed\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : array\n",
    "            reduced parameter array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        paramsfull : array\n",
    "            expanded parameter array where fixed parameters are included\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Calling this requires that self.fixed_params and self.fixed_paramsmask\n",
    "        are defined.\n",
    "\n",
    "        *developer notes:*\n",
    "\n",
    "        This can be used in the log-likelihood to ...\n",
    "\n",
    "        this could also be replaced by a more general parameter\n",
    "        transformation.\n",
    "\n",
    "        \"\"\"\n",
    "        paramsfull = self.fixed_params.copy()\n",
    "        paramsfull[self.fixed_paramsmask] = params\n",
    "        return paramsfull\n",
    "\n",
    "    def reduceparams(self, params):\n",
    "        \"\"\"Reduce parameters\"\"\"\n",
    "        return params[self.fixed_paramsmask]\n",
    "\n",
    "    def loglike(self, params):\n",
    "        \"\"\"Log-likelihood of model at params\"\"\"\n",
    "        return self.loglikeobs(params).sum(0)\n",
    "\n",
    "    def nloglike(self, params):\n",
    "        \"\"\"Negative log-likelihood of model at params\"\"\"\n",
    "        return -self.loglikeobs(params).sum(0)\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        \"\"\"Log-likelihood of individual observations at params\"\"\"\n",
    "        return -self.nloglikeobs(params)\n",
    "\n",
    "    def score(self, params):\n",
    "        \"\"\"\n",
    "        Gradient of log-likelihood evaluated at params\n",
    "        \"\"\"\n",
    "        kwds = {}\n",
    "        kwds.setdefault('centered', True)\n",
    "        return approx_fprime(params, self.loglike, **kwds).ravel()\n",
    "\n",
    "    def score_obs(self, params, **kwds):\n",
    "        \"\"\"\n",
    "        Jacobian/Gradient of log-likelihood evaluated at params for each\n",
    "        observation.\n",
    "        \"\"\"\n",
    "        kwds.setdefault('centered', True)\n",
    "        return approx_fprime(params, self.loglikeobs, **kwds)\n",
    "\n",
    "    def hessian(self, params):\n",
    "        \"\"\"\n",
    "        Hessian of log-likelihood evaluated at params\n",
    "        \"\"\"\n",
    "        from statsmodels.tools.numdiff import approx_hess\n",
    "        # need options for hess (epsilon)\n",
    "        return approx_hess(params, self.loglike)\n",
    "\n",
    "    def fit(self, cov_type=None, start_params=None, method='nm', maxiter=500, full_output=1,   # modified\n",
    "            disp=1, callback=None, retall=0, **kwargs):\n",
    "        \"\"\"\n",
    "        Fit the model using maximum likelihood.\n",
    "\n",
    "        The rest of the docstring is from\n",
    "        statsmodels.LikelihoodModel.fit\n",
    "        \"\"\"\n",
    "        if cov_type is None:          # modified\n",
    "            cov_type = 'nonrobust'    # modified\n",
    "\n",
    "        if start_params is None:\n",
    "            if hasattr(self, 'start_params'):\n",
    "                start_params = self.start_params\n",
    "            else:\n",
    "                start_params = 0.1 * np.ones(self.nparams)\n",
    "\n",
    "        fit_method = super(GenericLikelihoodModel_TobitTruncreg, self).fit\n",
    "        mlefit = fit_method(cov_type=cov_type, start_params=start_params,   # modified\n",
    "                            method=method, maxiter=maxiter,\n",
    "                            full_output=full_output,\n",
    "                            disp=disp, callback=callback, **kwargs)\n",
    "\n",
    "        # addition for modifincation starts ------------------------------------\n",
    "        # if 'Truncreg' in str(self.model.__class__):\n",
    "        if 'Truncreg' in str(self.__class__):\n",
    "            genericmlefit = GenericLikelihoodModelResults_Truncreg(self, mlefit, cov_type)\n",
    "        elif 'Tobit' in str(self.__class__):\n",
    "            genericmlefit = GenericLikelihoodModelResults_Tobit(self, mlefit, cov_type)\n",
    "        else:\n",
    "            pass\n",
    "        # addition for modifincation ends --------------------------------------\n",
    "\n",
    "        exog_names = [] if (self.exog_names is None) else self.exog_names\n",
    "        k_miss = len(exog_names) - len(mlefit.params)\n",
    "        if not k_miss == 0:\n",
    "            if k_miss < 0:\n",
    "                self._set_extra_params_names(['par%d' % i\n",
    "                                              for i in range(-k_miss)])\n",
    "            else:\n",
    "                import warnings\n",
    "                warnings.warn('more exog_names than parameters', ValueWarning)\n",
    "\n",
    "        return genericmlefit\n",
    "#-----\n",
    "\n",
    "#%% CommonAttributes_TobitTruncreg\n",
    "\n",
    "class CommonAttributes_TobitTruncreg(object):\n",
    "    # # Wald Test - all slopes=0\n",
    "    @cache_readonly\n",
    "    def wald_test_all_slopes(self):\n",
    "        _mat = np.eye(len(self.params))[1:-1,:]\n",
    "        return self.wald_test(_mat)\n",
    "\n",
    "    @cache_readonly\n",
    "    def prsquared(self):\n",
    "        \"\"\"\n",
    "        McFadden's pseudo-R-squared. `1 - (llf / llnull)`\n",
    "        \"\"\"\n",
    "        return 1 - self.llf/self.llnull\n",
    "\n",
    "    @cache_readonly\n",
    "    def llr(self):\n",
    "        \"\"\"\n",
    "        Likelihood ratio chi-squared statistic; `-2*(llnull - llf)`\n",
    "        under H0: all coefficients excluding constnat is zero\n",
    "        \"\"\"\n",
    "        return -2*(self.llnull - self.llf)\n",
    "\n",
    "    @cache_readonly\n",
    "    def llr_pvalue(self):\n",
    "        \"\"\"\n",
    "        p-value of likelihood ratio chi-squared statistic; `-2*(llnull - llf)`\n",
    "        with degrees of freedom `df_model`\n",
    "        under H0: all coefficients excluding constnat is zero\n",
    "        \"\"\"\n",
    "        return chi2.sf(self.llr, self.df_model)\n",
    "\n",
    "    @cache_readonly\n",
    "    def llnull(self):\n",
    "        \"\"\"\n",
    "        Value of loglikelihood with an Intercept only (no slope coefficients)\n",
    "        \"\"\"\n",
    "        return self.result_null.llf\n",
    "\n",
    "    def set_null_options(self, llnull=None, attach_results=True, **kwds):\n",
    "        \"\"\"set fit options for Null (constant-only) model\n",
    "\n",
    "        This resets the cache for related attributes which is potentially\n",
    "        fragile. This only sets the option, the null model is estimated\n",
    "        when llnull is accessed, if llnull is not yet in cache.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        llnull : None or float\n",
    "            If llnull is not None, then the value will be directly assigned to\n",
    "            the cached attribute \"llnull\".\n",
    "        attach_results : bool\n",
    "            Sets an internal flag whether the results instance of the null\n",
    "            model should be attached. By default without calling this method,\n",
    "            thenull model results are not attached and only the loglikelihood\n",
    "            value llnull is stored.\n",
    "        kwds : keyword arguments\n",
    "            `kwds` are directly used as fit keyword arguments for the null\n",
    "            model, overriding any provided defaults.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        no returns, modifies attributes of this instance\n",
    "\n",
    "        \"\"\"\n",
    "        self._cache.pop('llnull', None)\n",
    "        self._cache.pop('llr', None)\n",
    "        self._cache.pop('llr_pvalue', None)\n",
    "        self._cache.pop('prsquared', None)\n",
    "        if hasattr(self, 'result_null'):  # Tetsu\n",
    "            del self.result_null          # Tetsu\n",
    "\n",
    "        if llnull is not None:\n",
    "            self._cache['llnull'] = llnull\n",
    "        self._attach_nullmodel = attach_results\n",
    "        self._optim_kwds_null = kwds\n",
    "\n",
    "    @cache_readonly\n",
    "    def result_null(self):\n",
    "        \"\"\"\n",
    "        Value of loglikelihood with an Intercept only (no slope coefficients)\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        kwds = model._get_init_kwds().copy()\n",
    "        for key in getattr(model, '_null_drop_keys', []):\n",
    "            del kwds[key]\n",
    "\n",
    "        # the following lines are modified\n",
    "        if 'Truncreg' in str(model.__class__):\n",
    "            mod_null = model.__class__(model.endog, np.ones(self.nobs), left=model.left, right=model.right, **kwds)\n",
    "        elif 'Tobit' in str(model.__class__):\n",
    "            mod_null = model.__class__(model.endog, np.ones(self.nobs), cens=model.cens, left=model.left, right=model.right, **kwds)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        optim_kwds = getattr(self, '_optim_kwds_null', {}).copy()\n",
    "\n",
    "        if 'start_params' in optim_kwds:\n",
    "\n",
    "            sp_null = optim_kwds.pop('start_params')\n",
    "        elif hasattr(model, '_get_start_params_null'):\n",
    "\n",
    "            sp_null = model._get_start_params_null()\n",
    "        else:\n",
    "            sp_null = None\n",
    "\n",
    "        opt_kwds = dict(method='bfgs', warn_convergence=False, maxiter=10000,disp=0)\n",
    "        opt_kwds.update(optim_kwds)\n",
    "\n",
    "        if optim_kwds:\n",
    "            res_null = mod_null.fit(start_params=sp_null, **opt_kwds)\n",
    "        else:\n",
    "            res_null = mod_null.fit(start_params=sp_null, method='nm',\n",
    "                                    warn_convergence=False,\n",
    "                                    maxiter=10000, disp=0)\n",
    "\n",
    "        if getattr(self, '_attach_nullmodel', False) is not False:\n",
    "            self.res_null = res_null\n",
    "\n",
    "        return res_null\n",
    "#-----\n",
    "\n",
    "#%% AdditionalAttributes_Truncreg\n",
    "\n",
    "class AdditionalAttributes_Truncreg(object):\n",
    "    @cache_readonly\n",
    "    def fittedvalues(self):\n",
    "        \"\"\"\n",
    "        y_hat (Linear fitted values)\n",
    "        \"\"\"\n",
    "        return self.exog @ self.params[:-1].T\n",
    "\n",
    "    # residuals\n",
    "    @cache_readonly\n",
    "    def resid(self):\n",
    "        \"\"\"\n",
    "        Residuals = y - y_hat\n",
    "        \"\"\"\n",
    "        return self.endog - self.fittedvalues\n",
    "\n",
    "\n",
    "    @cache_readonly\n",
    "    def fitted_endog(self):\n",
    "        \"\"\"\n",
    "        E(y|x, cond)\n",
    "            cond for left-truncated: y > left-truncated value\n",
    "            cond for left-truncated: y < right-truncated value\n",
    "            cond for left- & right-truncated: left-truncated value < y < right-truncated value\n",
    "        Non-linear fitted endog variables (conditional expectations)\n",
    "        But, this attribute may be that useful\n",
    "        \"\"\"\n",
    "        s = self.params[-1]\n",
    "        sigma = np.exp(s)\n",
    "        Xb = self.fittedvalues\n",
    "        _l = self.model.left\n",
    "        _r = self.model.right\n",
    "\n",
    "        if ~np.isneginf(_l) & np.isposinf(_r):\n",
    "            first_term = Xb*norm.cdf(Xb, loc=_l, scale=sigma)\n",
    "            second_term = sigma*norm.pdf(Xb, loc=_l, scale=sigma)\n",
    "            return first_term + second_term\n",
    "\n",
    "        elif np.isneginf(_l) & ~np.isposinf(_r):\n",
    "            first_term = Xb*norm.sf(Xb, loc=_r, scale=sigma)\n",
    "            second_term = sigma*norm.pdf(Xb, loc=_r, scale=sigma)\n",
    "            return first_term - second_term\n",
    "\n",
    "        elif ~np.isneginf(_l) & ~np.isposinf(_r):\n",
    "            first_term = Xb*norm.cdf(Xb, loc=_l, scale=sigma)\n",
    "            second_term = Xb*norm.cdf(Xb, loc=_r, scale=sigma)\n",
    "            third_term = sigma*( norm.pdf(Xb, loc=_l, scale=sigma) - norm.pdf(Xb, loc=_r, scale=sigma) )\n",
    "            return first_term - second_term + third_term\n",
    "\n",
    "        else:\n",
    "            warnings.warn('\\n\\n**********************************************************************\\n\\n'+\n",
    "                          'Equivalent to untruncated Maximum Likelihood Estimation\\n\\n'+\n",
    "                          '**********************************************************************\\n')\n",
    "\n",
    "#-----\n",
    "\n",
    "#%% AdditionalAttributes_Tobit\n",
    "\n",
    "class AdditionalAttributes_Tobit(object):\n",
    "    @cache_readonly\n",
    "    def fittedvalues(self):\n",
    "        \"\"\"\n",
    "        y_hat (linear fiited latent variable)\n",
    "        \"\"\"\n",
    "        return self.exog @ self.params[:-1].T\n",
    "\n",
    "    # residuals\n",
    "    @cache_readonly\n",
    "    def resid(self):\n",
    "        \"\"\"\n",
    "        Residuals = y - y_hat\n",
    "        \"\"\"\n",
    "        return self.endog - self.fittedvalues\n",
    "\n",
    "    # non-linear fitted endog variables (conditional expectations)\n",
    "    @cache_readonly\n",
    "    def fitted_endog(self):\n",
    "        \"\"\"\n",
    "        E(y|x, cond)\n",
    "            cond for left-truncated: y > left-truncated value\n",
    "            cond for left-truncated: y < right-truncated value\n",
    "            cond for left- & right-truncated: left-truncated value < y < right-truncated value\n",
    "        Non-linear fitted endog variables (conditional expectations)\n",
    "        \"\"\"\n",
    "        s = self.params[-1]\n",
    "        sigma = np.exp(s)\n",
    "        Xb = self.fittedvalues\n",
    "        _l = self.model.left\n",
    "        _r = self.model.right\n",
    "        check_left = self.model.cens.unique().min()\n",
    "        check_right = self.model.cens.unique().max()\n",
    "\n",
    "        if (check_left == -1) & (check_right == 0):\n",
    "            first_term = (Xb-_l)*norm.cdf(Xb, loc=_l, scale=sigma)\n",
    "            second_term = sigma*norm.pdf(Xb, loc=_l, scale=sigma)\n",
    "            return _l + first_term + second_term\n",
    "\n",
    "        elif (check_left == 0) & (check_right == 1):\n",
    "            first_term = (Xb-_r)*norm.sf(Xb, loc=_r, scale=sigma)\n",
    "            second_term = sigma*norm.pdf(Xb, loc=_r, scale=sigma)\n",
    "            return _r + first_term - second_term\n",
    "\n",
    "        elif (check_left == -1) & (check_right == 1):\n",
    "            first_term = (Xb-_l)*norm.cdf(Xb, loc=_l, scale=sigma)\n",
    "            second_term = (Xb-_r)*norm.cdf(Xb, loc=_r, scale=sigma)\n",
    "            third_term = sigma*( norm.pdf(Xb, loc=_l, scale=sigma) - norm.pdf(Xb, loc=_r, scale=sigma) )\n",
    "            return _l + first_term - second_term + third_term\n",
    "\n",
    "        else:\n",
    "            warnings.warn('\\n\\n**********************************************************************\\n\\n'+\n",
    "                          'Equivalent to fitted_endog of uncensored Maximum Likelihood Estimation\\n\\n'+\n",
    "                          '**********************************************************************\\n')\n",
    "\n",
    "\n",
    "    # censoring\n",
    "    @cache_readonly\n",
    "    def obs(self):\n",
    "        \"\"\"\n",
    "        (no of obs, no of uncensored obs, no of left-censored obs, no of right-censored obs)\n",
    "        \"\"\"\n",
    "        censor = self.model.cens\n",
    "        num_minus_1 = len(censor[censor == -1])\n",
    "        num_0 = len(censor[censor == 0])\n",
    "        num_1 = len(censor[censor == 1])\n",
    "        uncensored = num_0\n",
    "        left_censored = num_minus_1\n",
    "        right_censored = num_1\n",
    "        return self.nobs,uncensored,left_censored,right_censored\n",
    "\n",
    "\n",
    "#-----\n",
    "\n",
    "#%% GenericLikelihoodModelResults_Truncreg\n",
    "\n",
    "class GenericLikelihoodModelResults_Truncreg(LikelihoodModelResults,\n",
    "                                             ResultMixin,\n",
    "                                             CommonAttributes_TobitTruncreg,\n",
    "                                             AdditionalAttributes_Truncreg):\n",
    "    \"\"\"\n",
    "    This is based on GenericLikelihoodModelResults of statsmodels (0.9.0).\n",
    "    Some attributes are added.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    aic : float\n",
    "        Akaike information criterion.  -2*(`llf` - p) where p is the number\n",
    "        of regressors including the intercept.\n",
    "    bic : float\n",
    "        Bayesian information criterion. -2*`llf` + ln(`nobs`)*p where p is the\n",
    "        number of regressors including the intercept.\n",
    "    bse : array\n",
    "        The standard errors of the coefficients.\n",
    "    df_resid : float\n",
    "        See model definition.\n",
    "    df_model : float\n",
    "        See model definition.\n",
    "    fitted_values : array\n",
    "        Linear predictor XB.\n",
    "    llf : float\n",
    "        Value of the loglikelihood\n",
    "    llnull : float\n",
    "        Value of the constant-only loglikelihood\n",
    "    llr : float\n",
    "        Likelihood ratio chi-squared statistic; -2*(`llnull` - `llf`)\n",
    "    llr_pvalue : float\n",
    "        The chi-squared probability of getting a log-likelihood ratio\n",
    "        statistic greater than llr.  llr has a chi-squared distribution\n",
    "        with degrees of freedom `df_model`.\n",
    "    prsquared : float\n",
    "        McFadden's pseudo-R-squared. 1 - (`llf`/`llnull`)\n",
    "    result_null:\n",
    "        result under H0: all slope coefficients are zero\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, mlefit, cov_type):\n",
    "        self.model = model\n",
    "        self.endog = model.endog\n",
    "        self.exog = model.exog\n",
    "        self.nobs = model.endog.shape[0]\n",
    "        self.cov_type = cov_type         # added\n",
    "\n",
    "        if hasattr(model, 'df_model'):\n",
    "            self.df_model = model.df_model\n",
    "        else:\n",
    "            self.df_model = len(mlefit.params)\n",
    "\n",
    "            self.model.df_model = self.df_model\n",
    "\n",
    "        if hasattr(model, 'df_resid'):\n",
    "            self.df_resid = model.df_resid\n",
    "        else:\n",
    "            self.df_resid = self.endog.shape[0] - self.df_model\n",
    "\n",
    "            self.model.df_resid = self.df_resid\n",
    "\n",
    "        self._cache = {}\n",
    "        self.__dict__.update(mlefit.__dict__)\n",
    "\n",
    "\n",
    "    def summary(self, yname=None, xname=None, title=None, alpha=.05):\n",
    "        \"\"\"Summarize the Regression Results\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        yname : string, optional\n",
    "            Default is `y`\n",
    "        xname : list of strings, optional\n",
    "            Default is `var_##` for ## in p the number of regressors\n",
    "        title : string, optional\n",
    "            Title for the top table. If not None, then this replaces the\n",
    "            default title\n",
    "        alpha : float\n",
    "            significance level for the confidence intervals\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        smry : Summary instance\n",
    "            this holds the summary tables and text, which can be printed or\n",
    "            converted to various output formats.\n",
    "\n",
    "        See Also\n",
    "        --------\n",
    "        statsmodels.iolib.summary.Summary : class to hold summary results\n",
    "        \"\"\"\n",
    "\n",
    "        # if 'truncreg' in str(self.model.__module__):\n",
    "        top_left = [('Dep. Variable:', None),\n",
    "                    ('Model:', None),\n",
    "                    ('Method:', ['Maximum Likelihood']),\n",
    "                    ('Date:', None),\n",
    "                    ('Time:', None),\n",
    "                    ('No. Observations:', None),\n",
    "                    ('Df Residuals:', None),\n",
    "                    ('Df Model:', None),\n",
    "                    ]\n",
    "\n",
    "        top_right = [('Pseudo R-squ:',[\"{:.3f}\".format(self.prsquared)]),\n",
    "                     ('Log-Likelihood:', [\"{:.1f}\".format(self.llf)]),\n",
    "                     ('LL-Null:', [\"{:.1f}\".format(self.llnull)]),\n",
    "                     ('LL-Ratio:', [\"{:.1f}\".format(self.llr)]),\n",
    "                     ('LLR p-value:', [\"{:.3f}\".format(self.llr_pvalue)]),\n",
    "                     ('AIC:', [\"{:.1f}\".format(self.aic)]),\n",
    "                     ('BIC:', [\"{:.1f}\".format(self.bic)]),\n",
    "                     ('Covariance Type:', [self.cov_type]),\n",
    "                     ]\n",
    "\n",
    "        if title is None:\n",
    "            title = self.model.__class__.__name__ + ' ' + \"Regression Results\"\n",
    "\n",
    "        # create summary table instance\n",
    "        from statsmodels.iolib.summary import Summary\n",
    "        smry = Summary()\n",
    "        smry.add_table_2cols(self, gleft=top_left, gright=top_right,\n",
    "                             yname=yname, xname=xname, title=title)\n",
    "        smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha,\n",
    "                              use_t=self.use_t)\n",
    "\n",
    "        return smry\n",
    "#-----\n",
    "\n",
    "#%% GenericLikelihoodModelResults_Tobit\n",
    "\n",
    "class GenericLikelihoodModelResults_Tobit(LikelihoodModelResults,\n",
    "                                          ResultMixin,\n",
    "                                          CommonAttributes_TobitTruncreg,\n",
    "                                          AdditionalAttributes_Tobit):\n",
    "    \"\"\"\n",
    "    This is based on GenericLikelihoodModelResults of statsmodels (0.9.0).\n",
    "    Some attributes are added.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    aic : float\n",
    "        Akaike information criterion.  -2*(`llf` - p) where p is the number\n",
    "        of regressors including the intercept.\n",
    "    bic : float\n",
    "        Bayesian information criterion. -2*`llf` + ln(`nobs`)*p where p is the\n",
    "        number of regressors including the intercept.\n",
    "    bse : array\n",
    "        The standard errors of the coefficients.\n",
    "    df_resid : float\n",
    "        See model definition.\n",
    "    df_model : float\n",
    "        See model definition.\n",
    "    fitted_values : array\n",
    "        Linear predictor XB.\n",
    "    llf : float\n",
    "        Value of the loglikelihood\n",
    "    llnull : float\n",
    "        Value of the constant-only loglikelihood\n",
    "    llr : float\n",
    "        Likelihood ratio chi-squared statistic; -2*(`llnull` - `llf`)\n",
    "    llr_pvalue : float\n",
    "        The chi-squared probability of getting a log-likelihood ratio\n",
    "        statistic greater than llr.  llr has a chi-squared distribution\n",
    "        with degrees of freedom `df_model`.\n",
    "    prsquared : float\n",
    "        McFadden's pseudo-R-squared. 1 - (`llf`/`llnull`)\n",
    "    result_null:\n",
    "        result under H0: all slope coefficients are zero\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, mlefit, cov_type):\n",
    "        self.model = model\n",
    "        self.endog = model.endog\n",
    "        self.exog = model.exog\n",
    "        self.nobs = model.endog.shape[0]\n",
    "        self.cov_type = cov_type         # added\n",
    "\n",
    "        if hasattr(model, 'df_model'):\n",
    "            self.df_model = model.df_model\n",
    "        else:\n",
    "            self.df_model = len(mlefit.params)\n",
    "\n",
    "            self.model.df_model = self.df_model\n",
    "\n",
    "        if hasattr(model, 'df_resid'):\n",
    "            self.df_resid = model.df_resid\n",
    "        else:\n",
    "            self.df_resid = self.endog.shape[0] - self.df_model\n",
    "\n",
    "            self.model.df_resid = self.df_resid\n",
    "\n",
    "        self._cache = {}\n",
    "        self.__dict__.update(mlefit.__dict__)\n",
    "\n",
    "\n",
    "    def summary(self, yname=None, xname=None, title=None, alpha=.05):\n",
    "        \"\"\"Summarize the Regression Results\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        yname : string, optional\n",
    "            Default is `y`\n",
    "        xname : list of strings, optional\n",
    "            Default is `var_##` for ## in p the number of regressors\n",
    "        title : string, optional\n",
    "            Title for the top table. If not None, then this replaces the\n",
    "            default title\n",
    "        alpha : float\n",
    "            significance level for the confidence intervals\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        smry : Summary instance\n",
    "            this holds the summary tables and text, which can be printed or\n",
    "            converted to various output formats.\n",
    "\n",
    "        See Also\n",
    "        --------\n",
    "        statsmodels.iolib.summary.Summary : class to hold summary results\n",
    "        \"\"\"\n",
    "\n",
    "        top_left = [('Dep. Variable:', None),\n",
    "                    # ('Model:', None),\n",
    "                    ('Method:', ['Maximum Likelihood']),\n",
    "                    # ('Date:', None),\n",
    "                    # ('Time:', None),\n",
    "                    ('No. Observations:', None),\n",
    "                    ('No. Uncensored Obs:', [\"{:.0f}\".format(self.obs[1])]),\n",
    "                    ('No. Left-censored Obs:', [\"{:.0f}\".format(self.obs[2])]),\n",
    "                    ('No. Right-censored Obs:', [\"{:.0f}\".format(self.obs[3])]),\n",
    "                    ('Df Residuals:', None),\n",
    "                    ('Df Model:', None),\n",
    "                    ]\n",
    "\n",
    "        top_right = [('Pseudo R-squ:',[\"{:.3f}\".format(self.prsquared)]),\n",
    "                     ('Log-Likelihood:', [\"{:.1f}\".format(self.llf)]),\n",
    "                     ('LL-Null:', [\"{:.1f}\".format(self.llnull)]),\n",
    "                     ('LL-Ratio:', [\"{:.1f}\".format(self.llr)]),\n",
    "                     ('LLR p-value:', [\"{:.3f}\".format(self.llr_pvalue)]),\n",
    "                     ('AIC:', [\"{:.1f}\".format(self.aic)]),\n",
    "                     ('BIC:', [\"{:.1f}\".format(self.bic)]),\n",
    "                     ('Covariance Type:', [self.cov_type]),\n",
    "                     ]\n",
    "\n",
    "        if title is None:\n",
    "            title = self.model.__class__.__name__ + ' ' + \"Regression Results\"\n",
    "\n",
    "        # create summary table instance\n",
    "        from statsmodels.iolib.summary import Summary\n",
    "        smry = Summary()\n",
    "        smry.add_table_2cols(self, gleft=top_left, gright=top_right,\n",
    "                             yname=yname, xname=xname, title=title)\n",
    "        smry.add_table_params(self, yname=yname, xname=xname, alpha=alpha,\n",
    "                              use_t=self.use_t)\n",
    "\n",
    "        return smry\n",
    "#-----\n",
    "\n",
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created by Tetsu Haruyama\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "#from py4etrics.base_for_models import GenericLikelihoodModel_TobitTruncreg\n",
    "\n",
    "class Tobit(GenericLikelihoodModel_TobitTruncreg):\n",
    "    \"\"\"\n",
    "    Create a Seires or array (to be used for \"<censor>\" below)\n",
    "           -1: left-censored\n",
    "            0: uncensored\n",
    "            1: right-censored\n",
    "\n",
    "    Method 1:\n",
    "    Tobit(endog, exog, cens=<censor>, left=<0>, right=<0>).fit()\n",
    "    endog = dependent variable\n",
    "    exog = independent variable (add constant if needed)\n",
    "    cens = see above\n",
    "    left = the threshold value for left-censoring (default:0)\n",
    "        　　(This becomes effective only if -1 is set in <censor>)\n",
    "    right = the threshold value for right-censoring (default:0)\n",
    "        　　(This becomes effective only if 1 is set in <censor>)\n",
    "          \n",
    "    Method 2:\n",
    "    formula = 'y ~ 1 + x'\n",
    "    Tobit.from_formula(formula, cens=<censor>, left=<0>, right=<0>, data=<DATA>).fit()\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, endog, exog, cens, left=None, right=None, **kwds):\n",
    "        super(Tobit, self).__init__(endog, exog, **kwds)\n",
    "        self.cens = cens\n",
    "        if left is None:\n",
    "            left = 0\n",
    "        self.left = left\n",
    "        if right is None:\n",
    "            right = 0\n",
    "        self.right = right\n",
    "\n",
    "    def loglikeobs(self, params): # see _tobit()\n",
    "#     def loglike(self, params): # see _tobit()\n",
    "\n",
    "        s = params[-1]\n",
    "        beta = params[:-1]\n",
    "\n",
    "        def _tobit(y, x, z, left, right, beta, s):\n",
    "            if ( ~np.isin(z,[-1,0,1]) ).any():\n",
    "                warnings.warn('\\n\\n***************************************************\\n\\n'+\n",
    "                              'There are values other than [-1,0,1] in a column for cens\\n\\n'+\n",
    "                             '***************************************************\\n')\n",
    "\n",
    "            # indicators\n",
    "            left_on  = np.where(z==-1, 1, 0)\n",
    "            mid_on   = np.where(z== 0, 1, 0)\n",
    "            right_on = np.where(z== 1, 1, 0)\n",
    "\n",
    "            Xb = np.dot(x, beta)\n",
    "\n",
    "            # Eqn 5 of https://cran.r-project.org/web/packages/censReg/vignettes/censReg.pdf\n",
    "            # scale=np.exp(s)\n",
    "            left_mle  = left_on *  norm.logcdf( (left-Xb)  / np.exp(s) )\n",
    "            mid_mle   = mid_on * ( norm.logpdf( (y-Xb)     / np.exp(s) ) - s )\n",
    "            right_mle = right_on * norm.logcdf( (Xb-right) / np.exp(s) )\n",
    "            \n",
    "            return left_mle + mid_mle + right_mle  #  loglikeobs()                        \n",
    "#             return (left_mle+mid_mle+right_mle).sum()  #  loglike()\n",
    "\n",
    "        return _tobit(self.endog, self.exog, self.cens, self.left, self.right, beta, s)\n",
    "\n",
    "    def fit(self, cov_type='nonrobust', start_params=None, maxiter=10000, maxfun=10000, **kwds):\n",
    "        \n",
    "        # add sigma for summary\n",
    "        if 'Log(Sigma)' not in self.exog_names:  # ML Case 1 is used\n",
    "            self.exog_names.append('Log(Sigma)')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # initial guess\n",
    "        res = sm.OLS(self.endog, self.exog).fit()\n",
    "        ols_params = res.params\n",
    "        ols_sigma = np.log(np.std(res.resid))\n",
    "        \n",
    "        # option\n",
    "        if start_params == None:\n",
    "            start_params = np.append(ols_params, ols_sigma)\n",
    "\n",
    "        res = super(Tobit, self).fit(cov_type=cov_type, start_params=start_params,\n",
    "                                     maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "random.seed(32)\n",
    "from matplotlib import pyplot as plt\n",
    "x = np.arange(0,10,0.5)\n",
    "\n",
    "y_real = np.array([i*0.3-1.1 for i in x])\n",
    "y_sampled = np.array([(i+random.gauss(0,0.4)) for i in y_real])\n",
    "y_sampled_truncated = np.where(y_sampled<0,0,y_sampled)\n",
    "plt.plot(x,y_real,label='real',ls='--',c='r')\n",
    "plt.scatter(x,y_sampled_truncated,label='sampled')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(-1,1)\n",
    "x = np.concatenate([x,np.ones((len(x),1))],axis=1)\n",
    "y_sampled_truncated = y_sampled_truncated.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19302975],\n",
       "       [-0.29385029]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the regression using the normal equation\n",
    "beta = scipy.linalg.inv(x.T@x)@(x.T)@y_sampled_truncated\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = x@beta\n",
    "\n",
    "plt.plot(x[:,0].ravel(),y_real,label='real',ls='-',c='r')\n",
    "plt.scatter(x[:,0].ravel(),y_sampled_truncated,label='data')\n",
    "plt.plot(x[:,0].ravel(),pred_y,label='ols',c='g',ls='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511606\n",
      "         Iterations: 42\n",
      "         Function evaluations: 73\n"
     ]
    }
   ],
   "source": [
    "tob = Tobit(y_sampled,x,0)\n",
    "tob_fit = tob.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tob_fit\u001b[39m.\u001b[39;49msummary()\n",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 8\u001b[0m in \u001b[0;36mGenericLikelihoodModelResults_Tobit.summary\u001b[0;34m(self, yname, xname, title, alpha)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=647'>648</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummary\u001b[39m(\u001b[39mself\u001b[39m, yname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, xname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39m.05\u001b[39m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=648'>649</a>\u001b[0m     \u001b[39m\"\"\"Summarize the Regression Results\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=649'>650</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=650'>651</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=670'>671</a>\u001b[0m \u001b[39m    statsmodels.iolib.summary.Summary : class to hold summary results\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=671'>672</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=673'>674</a>\u001b[0m     top_left \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mDep. Variable:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=674'>675</a>\u001b[0m                 \u001b[39m# ('Model:', None),\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=675'>676</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mMethod:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mMaximum Likelihood\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=676'>677</a>\u001b[0m                 \u001b[39m# ('Date:', None),\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=677'>678</a>\u001b[0m                 \u001b[39m# ('Time:', None),\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=678'>679</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mNo. Observations:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=679'>680</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mNo. Uncensored Obs:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs[\u001b[39m1\u001b[39m])]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=680'>681</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mNo. Left-censored Obs:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs[\u001b[39m2\u001b[39m])]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=681'>682</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mNo. Right-censored Obs:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs[\u001b[39m3\u001b[39m])]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=682'>683</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mDf Residuals:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=683'>684</a>\u001b[0m                 (\u001b[39m'\u001b[39m\u001b[39mDf Model:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=684'>685</a>\u001b[0m                 ]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=686'>687</a>\u001b[0m     top_right \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mPseudo R-squ:\u001b[39m\u001b[39m'\u001b[39m,[\u001b[39m\"\u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprsquared)]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=687'>688</a>\u001b[0m                  (\u001b[39m'\u001b[39m\u001b[39mLog-Likelihood:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllf)]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=688'>689</a>\u001b[0m                  (\u001b[39m'\u001b[39m\u001b[39mLL-Null:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m{:.1f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllnull)]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=693'>694</a>\u001b[0m                  (\u001b[39m'\u001b[39m\u001b[39mCovariance Type:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_type]),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=694'>695</a>\u001b[0m                  ]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=696'>697</a>\u001b[0m     \u001b[39mif\u001b[39;00m title \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 8\u001b[0m in \u001b[0;36mAdditionalAttributes_Tobit.obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=437'>438</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=438'>439</a>\u001b[0m \u001b[39m(no of obs, no of uncensored obs, no of left-censored obs, no of right-censored obs)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=439'>440</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=440'>441</a>\u001b[0m censor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcens\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=441'>442</a>\u001b[0m num_minus_1 \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(censor[censor \u001b[39m==\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=442'>443</a>\u001b[0m num_0 \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(censor[censor \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X13sZmlsZQ%3D%3D?line=443'>444</a>\u001b[0m num_1 \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(censor[censor \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "tob_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tob_fit\u001b[39m.\u001b[39;49mpredict()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:1159\u001b[0m, in \u001b[0;36mResults.predict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         exog \u001b[39m=\u001b[39m exog[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m   1157\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_2d(exog)  \u001b[39m# needed in count model shape[1]\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m predict_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, exog, \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m   1160\u001b[0m                                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m exog_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(predict_results,\n\u001b[1;32m   1163\u001b[0m                                           \u001b[39m'\u001b[39m\u001b[39mpredicted_values\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1164\u001b[0m     \u001b[39mif\u001b[39;00m predict_results\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:258\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, params, exog, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, params, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    253\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m    After a model has been fit predict returns the fitted values.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[39m    This is a placeholder intended to be overwritten by individual models.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tob_fit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin, MultiOutputMixin\n",
    "from sklearn.linear_model._base import LinearModel, _preprocess_data, _check_sample_weight,_rescale_data\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "#from sklearn.utils.parallel import delayed, Parallel\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import optimize\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import lsqr\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Tobit(MultiOutputMixin, RegressorMixin, LinearModel):\n",
    "    ''' \n",
    "    Simple implementation of tobit regression.\n",
    "\n",
    "    Uses the loglikehood function as a loss.\n",
    "\n",
    "    Doesn't accept sparse matrix for now.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, *, fit_intercept=True, copy_X=True, n_jobs=None, positive=False):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "        self.positive = positive\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Fit linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary.\n",
    "\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Individual weights for each sample.\n",
    "\n",
    "            .. versionadded:: 0.17\n",
    "               parameter *sample_weight* support to LinearRegression.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted Estimator.\n",
    "        \"\"\"\n",
    "\n",
    "        #self._validate_params()\n",
    "\n",
    "        n_jobs_ = self.n_jobs\n",
    "\n",
    "        accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\n",
    "\n",
    "        X, y = self._validate_data(\n",
    "            X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True\n",
    "        )\n",
    "\n",
    "        sample_weight = _check_sample_weight(\n",
    "            sample_weight, X, dtype=X.dtype\n",
    "        )\n",
    "\n",
    "        X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
    "            X,\n",
    "            y,\n",
    "            fit_intercept=self.fit_intercept,\n",
    "            copy=self.copy_X,\n",
    "            sample_weight=sample_weight,\n",
    "        )\n",
    "\n",
    "        # Sample weight can be implemented via a simple rescaling.\n",
    "        X, y = _rescale_data(X, y, sample_weight)\n",
    "\n",
    "        # fitting with the loglikelihood function\n",
    "        self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y)\n",
    "        self.coef_ = self.coef_.T\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            self.coef_ = np.ravel(self.coef_)\n",
    "        self._set_intercept(X_offset, y_offset, X_scale)\n",
    "        return self\n",
    "\n",
    "\n",
    "def tobit_loss(threshold,sigma,y_real,y_pred):\n",
    "    log_lkhd_left = np.log((1/sigma)*(y_real-y_pred)/sigma)\n",
    "    log_lkhd_right = np.log((threshold-y_pred)/sigma)\n",
    "    return np.sum(log_lkhd_left) + np.sum(log_lkhd_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y_sampled_truncated \u001b[39m=\u001b[39m y_sampled_truncated\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m reg_tobit \u001b[39m=\u001b[39m Tobit()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m reg_tobit\u001b[39m.\u001b[39;49mfit(x,y_sampled_truncated)\n",
      "\u001b[1;32m/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb Cell 11\u001b[0m in \u001b[0;36mTobit.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     X,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m X, y, sample_weight_sqrt \u001b[39m=\u001b[39m _rescale_data(X, y, sample_weight)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# fitting with the loglikelihood function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cemlyncoirier-roberts/Documents/UK-Housing-Market/Tobit/Tobit.ipynb#X16sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingular_ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mlstsq(X, y)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "random.seed(32)\n",
    "from matplotlib import pyplot as plt\n",
    "x = np.arange(0,10,0.5)\n",
    "\n",
    "y_real = np.array([i*0.3-1.1 for i in x])\n",
    "y_sampled = np.array([(i+random.gauss(0,0.4)) for i in y_real])\n",
    "y_sampled_truncated = np.where(y_sampled<0,0,y_sampled)\n",
    "\n",
    "x = x.reshape(-1,1)\n",
    "y_sampled_truncated = y_sampled_truncated.reshape(-1,1)\n",
    "\n",
    "reg_tobit = Tobit()\n",
    "reg_tobit.fit(x,y_sampled_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
